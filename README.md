## Topic Modeling from Scratch

ğŸ“Œ Overview

This repository contains an implementation of topic modeling from scratch using Latent Dirichlet Allocation (LDA). The project includes a collapsed Gibbs sampler to estimate the topic distributions and infer latent topics from a collection of documents.

ğŸ›  Features
* Implements LDA from scratch without using existing libraries like `gensim` or `scikit-learn`
* Uses collapsed Gibbs sampling for topic inference
* Provides document-topic and word-topic distributions

ğŸ“‚ Repository Structure 
```
ğŸ“ topic_modelling_from_scratch  
â”‚â”€â”€ ğŸ“„ LDA.py   # Implementation of LDA with Gibbs Sampling  
â”‚â”€â”€ ğŸ“„ main.py   # runner script   
â”‚â”€â”€ ğŸ“ utils/ 
  â”‚â”€â”€ ğŸ“„ utils.py # helper functions such as reading from text files 
  â”‚â”€â”€ ğŸ“„ evaluation.py # evaluation functions for the ML model  
  â”‚â”€â”€ ğŸ“„ logistic_regression.py # Script to build, train and test the classification model 
â”‚â”€â”€ ğŸ“ data/  # folder containing different datasets for topic classification 
  â”‚â”€â”€ ğŸ“ 20newsgroups/   # contains 884 documents  
  â”‚â”€â”€ ğŸ“ artificial/   # contains 10 documents  
â”‚â”€â”€ ğŸ“ config \
  â”‚â”€â”€ ğŸ“„ config.py   # creates a config class to be used in runner scripts 
  â”‚â”€â”€ ğŸ“„ config.json   # contains all the tunable parameters the user can 
â”‚â”€â”€ ğŸ“„ requirements.txt # contains required Python packages and versions 
â”‚â”€â”€ ğŸ“„ README.md     # This file
```
